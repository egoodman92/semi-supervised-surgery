{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our beautiful packages\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect list of breast videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pasteur/u/egoodma/data/videos/breast\n"
     ]
    }
   ],
   "source": [
    "%cd /pasteur/u/egoodma/data/videos/breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm breast_names.txt\n",
    "for entry in *\n",
    "do\n",
    "  echo \"$entry\" >> breast_names.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studying 128 breast videos\n"
     ]
    }
   ],
   "source": [
    "with open(\"breast_names.txt\") as f:\n",
    "    breast_videos = f.readlines()\n",
    "breast_videos = [x.strip() for x in breast_videos]\n",
    "breast_videos = [vid for vid in breast_videos if len(vid) == 15]\n",
    "breast_videos = set(breast_videos)\n",
    "print(\"Studying {} breast videos\".format(len(breast_videos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect list of gastro videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pasteur/u/egoodma/data/videos/gastro\n"
     ]
    }
   ],
   "source": [
    "%cd /pasteur/u/egoodma/data/videos/gastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm gastro_names.txt\n",
    "for entry in *\n",
    "do\n",
    "  echo \"$entry\" >> gastro_names.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gastro_names.txt\") as f:\n",
    "    gastro_videos = f.readlines()\n",
    "gastro_videos = [x.strip() for x in gastro_videos]\n",
    "gastro_videos = [vid for vid in gastro_videos if len(vid) == 15]\n",
    "gastro_videos = set(gastro_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect list of head videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pasteur/u/egoodma/data/videos/head\n"
     ]
    }
   ],
   "source": [
    "%cd /pasteur/u/egoodma/data/videos/head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm head_names.txt\n",
    "for entry in *\n",
    "do\n",
    "  echo \"$entry\" >> head_names.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"head_names.txt\") as f:\n",
    "    head_videos = f.readlines()\n",
    "head_videos = [x.strip() for x in head_videos]\n",
    "head_videos = [vid for vid in head_videos if len(vid) == 15]\n",
    "head_videos = set(head_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis now with data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 128 breast videos, 155 gastro videos, and 54 head videos\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing {} breast videos, {} gastro videos, and {} head videos\".format(len(breast_videos), len(gastro_videos), len(head_videos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pasteur/u/egoodma/surgery-action-recognition\n",
      "['background', 'background', 'cutting', 'background', 'background', 'background', 'background', 'background', 'background', 'cutting', 'background', 'background', 'background', 'cutting', 'background', 'background', 'cutting', 'background', 'cutting', 'cutting', 'background', 'background', 'cutting', 'cutting', 'cutting', 'cutting', 'cutting', 'cutting', 'cutting', 'cutting', 'cutting', 'background', 'background', 'cutting', 'cutting', 'cutting', 'cutting', 'background']\n",
      "1\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "[0.05263157894736842, 0.02631578947368421, 0.15789473684210525, 0.02631578947368421, 0.07894736842105263, 0.02631578947368421, 0.05263157894736842, 0.02631578947368421, 0.02631578947368421, 0.05263157894736842, 0.05263157894736842, 0.23684210526315788, 0.05263157894736842, 0.10526315789473684, 0.02631578947368421]\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "#this creates sequence_dict, mapping videos to sequences      #\n",
    "#sequence_dict[video] = [\"cutting\", \"cutting\", ... \"suturing\"]#\n",
    "#this also create label_dict, mapping videos to class labels  #\n",
    "#label_dict[video] = 1                                        #\n",
    "###############################################################\n",
    "%cd /pasteur/u/egoodma/surgery-action-recognition\n",
    "\n",
    "sequence_dict = dict()\n",
    "label_dict = dict()\n",
    "\n",
    "with open('v0.6.0-preds.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    next(readCSV)\n",
    "    rows = 0\n",
    "    for row in readCSV:\n",
    "        rows += 1\n",
    "        movie_name = row[0]\n",
    "        if movie_name not in sequence_dict:\n",
    "            sequence_dict[movie_name] = []\n",
    "            if movie_name+'.mp4' in breast_videos:\n",
    "                label_dict[movie_name] = 0\n",
    "            elif movie_name+'.mp4' in gastro_videos:\n",
    "                label_dict[movie_name] = 1\n",
    "            elif movie_name+'.mp4' in head_videos:\n",
    "                label_dict[movie_name] = 2\n",
    "            else:\n",
    "                print(\"Couldn't find movie!!!\")\n",
    "                break\n",
    "        for i in range(int(int(row[1])/5)):\n",
    "            sequence_dict[movie_name].append(row[2])\n",
    "        \n",
    "        \n",
    "############################################################\n",
    "#creates action_dict, another representation of a video    #\n",
    "#this moves from action to action, and is paired with      #\n",
    "#time-dict, the corresponding duration of the action (secs)# \n",
    "############################################################\n",
    "\n",
    "#background = 0, cutting = 1, suturing = 2, tying = 3\n",
    "time_dict = dict()\n",
    "action_dict = dict()\n",
    "for video in sequence_dict:\n",
    "    time_dict[video] = [5]\n",
    "    action_dict[video] = [sequence_dict[video][0]]\n",
    "    #print(\"Studying video {}\".format(video))\n",
    "    for t in range(1, len(sequence_dict[video])):\n",
    "        if sequence_dict[video][t] == action_dict[video][-1]:\n",
    "            time_dict[video][-1] += 5\n",
    "        else:\n",
    "            action_dict[video].append(sequence_dict[video][t])\n",
    "            time_dict[video].append(5)\n",
    "               \n",
    "for video in action_dict:\n",
    "    total_time = sum(time_dict[video])\n",
    "    for i, action in enumerate(action_dict[video]):\n",
    "        if action == \"background\":\n",
    "            action_dict[video][i] = 0\n",
    "        elif action == \"cutting\":\n",
    "            action_dict[video][i] = 1\n",
    "        elif action == \"suturing\":\n",
    "            action_dict[video][i] = 2\n",
    "        elif action == \"tying\":\n",
    "            action_dict[video][i] = 3\n",
    "        time_dict[video][i] /= total_time\n",
    "        \n",
    "####################################\n",
    "#now we will show a couple examples#                         \n",
    "####################################\n",
    "print(sequence_dict[\"bxm902jT1Ok\"])\n",
    "print(label_dict[\"bxm902jT1Ok\"])\n",
    "print(action_dict[\"bxm902jT1Ok\"])\n",
    "print(time_dict[\"bxm902jT1Ok\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast complexity 15.89090909090909, gastro complexity 20.968992248062015, head complexity 23.1875\n",
      "Breast complexity 13.959907172487316, gastro complexity 17.833831617104238, head complexity 18.437570621333677\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################################\n",
    "#now we want to get the 'complexity' of each action         #\n",
    "#to see if certain types of surgeries are more complex      #\n",
    "#we define complexity as times swapped between tasks        #\n",
    "#############################################################\n",
    "breast_complexity, gastro_complexity, head_complexity = [], [], []\n",
    "for video in action_dict:\n",
    "    if video+\".mp4\" in breast_videos:\n",
    "        breast_complexity.append(len(action_dict[video]) - 1)\n",
    "    elif video+\".mp4\" in gastro_videos:\n",
    "        gastro_complexity.append(len(action_dict[video]) - 1)\n",
    "    elif video+\".mp4\" in head_videos:\n",
    "        head_complexity.append(len(action_dict[video]) - 1)\n",
    "        \n",
    "print(\"Breast complexity {}, gastro complexity {}, head complexity {}\"\\\n",
    "      .format(np.mean(breast_complexity), np.mean(gastro_complexity), np.mean(head_complexity)))\n",
    "print(\"Breast complexity {}, gastro complexity {}, head complexity {}\"\\\n",
    "      .format(np.std(breast_complexity), np.std(gastro_complexity), np.std(head_complexity)))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "_ = plt.hist(breast_complexity, 10)\n",
    "_ = plt.hist(gastro_complexity, 10)\n",
    "_ = plt.hist(head_complexity, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38181818 0.40909091 0.17272727 1.40909091 0.4        0.94545455\n",
      " 4.60909091 0.89090909 0.60909091 4.41818182 0.57272727 1.07272727] is breast representation\n",
      "[0.84496124 0.74418605 0.52713178 3.24031008 0.75193798 2.40310078\n",
      " 4.20930233 1.20155039 0.90697674 3.95348837 0.6124031  1.57364341] is gastro representation\n",
      "[0.70833333 1.10416667 0.5        1.60416667 1.14583333 1.33333333\n",
      " 6.83333333 0.77083333 0.89583333 6.60416667 0.64583333 1.04166667] is head representation\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1730d6a280>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################################\n",
    "#now we want to get the transition types of surgeries       #\n",
    "#############################################################\n",
    "\n",
    "\n",
    "def analyze_video(video, sequence_dict):\n",
    "    video_rep = [0]*12\n",
    "    for i in range(len(sequence_dict[video]) - 1):\n",
    "        if sequence_dict[video][i] == \"cutting\" and sequence_dict[video][i+1] == \"suturing\":\n",
    "            video_rep[0] += 1\n",
    "        if sequence_dict[video][i] == \"cutting\" and sequence_dict[video][i+1] == \"tying\":\n",
    "            video_rep[1] += 1\n",
    "        if sequence_dict[video][i] == \"suturing\" and sequence_dict[video][i+1] == \"cutting\":\n",
    "            video_rep[2] += 1\n",
    "        if sequence_dict[video][i] == \"suturing\" and sequence_dict[video][i+1] == \"tying\":\n",
    "            video_rep[3] += 1\n",
    "        if sequence_dict[video][i] == \"tying\" and sequence_dict[video][i+1] == \"cutting\":\n",
    "            video_rep[4] += 1\n",
    "        if sequence_dict[video][i] == \"tying\" and sequence_dict[video][i+1] == \"suturing\":\n",
    "            video_rep[5] += 1\n",
    "        if sequence_dict[video][i] == \"background\" and sequence_dict[video][i+1] == \"cutting\":\n",
    "            video_rep[6] += 1\n",
    "        if sequence_dict[video][i] == \"background\" and sequence_dict[video][i+1] == \"suturing\":\n",
    "            video_rep[7] += 1\n",
    "        if sequence_dict[video][i] == \"background\" and sequence_dict[video][i+1] == \"tying\":\n",
    "            video_rep[8] += 1\n",
    "        if sequence_dict[video][i] == \"cutting\" and sequence_dict[video][i+1] == \"background\":\n",
    "            video_rep[9] += 1\n",
    "        if sequence_dict[video][i] == \"suturing\" and sequence_dict[video][i+1] == \"background\":\n",
    "            video_rep[10] += 1\n",
    "        if sequence_dict[video][i] == \"tying\" and sequence_dict[video][i+1] == \"background\":\n",
    "            video_rep[11] += 1\n",
    "    if sum(video_rep) == 0:\n",
    "        return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    return [x / 1 for x in video_rep]\n",
    "\n",
    "breast_trans, gastro_trans, head_trans = [], [], []\n",
    "for video in action_dict:\n",
    "    video_rep = analyze_video(video, sequence_dict)\n",
    "    if video+\".mp4\" in breast_videos:\n",
    "        breast_trans.append(video_rep)\n",
    "    elif video+\".mp4\" in gastro_videos:\n",
    "        gastro_trans.append(video_rep)\n",
    "    elif video+\".mp4\" in head_videos:\n",
    "        head_trans.append(video_rep)\n",
    "\n",
    "breast_trans = np.asarray(breast_trans)\n",
    "gastro_trans = np.asarray(gastro_trans)\n",
    "head_trans = np.asarray(head_trans)\n",
    "\n",
    "print(np.mean(breast_trans, axis = 0), \"is breast representation\")\n",
    "print(np.mean(gastro_trans, axis = 0), \"is gastro representation\")\n",
    "print(np.mean(head_trans, axis = 0), \"is head representation\")\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "#cutting->suturing in 0\n",
    "#cutting->tying in 1\n",
    "#suturing->cutting in 2\n",
    "#suturing->tying in 3\n",
    "#tying->cutting in 4\n",
    "#tying->cutting in 5\n",
    "\n",
    "###############################\n",
    "#plotting numhands vs numtools#\n",
    "###############################\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(breast_trans[:, 3], breast_trans[:, 4], s=100, c='b', marker=\"s\")\n",
    "ax1.scatter(gastro_trans[:, 3], gastro_trans[:, 4], s=100, c='r', marker=\"o\")\n",
    "ax1.scatter(head_trans[:, 3], head_trans[:, 4], s=150, c='g', marker=\"*\")\n",
    "plt.xlabel('Average number of hands', fontsize=18)\n",
    "plt.ylabel('Average number of tools', fontsize=18)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=18)\n",
    "\n",
    "plt.legend(('breast', 'gastrointestinal', 'head-and-neck'),\n",
    "           loc='upper right', prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (229, 12), X_test (58, 12), y_train (229, 1), y_test (58, 1)\n",
      "Accurate percentage is 51.96506550218341 \n",
      "\n",
      "Coefficients are [[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.11021807  0.          0.\n",
      "   0.          0.          0.         -0.06110508  0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]]\n",
      "Accurate percentage is 60.3448275862069\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate((breast_trans, gastro_trans, head_trans), axis = 0)\n",
    "y = np.concatenate((np.zeros((breast_trans.shape[0], 1)), np.ones((gastro_trans.shape[0], 1)), \\\n",
    "                    2*np.ones((head_trans.shape[0], 1))), axis = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=102)\n",
    "\n",
    "print(\"X_train {}, X_test {}, y_train {}, y_test {}\"\\\n",
    "      .format(X_train.shape,  X_test.shape, y_train.shape, y_test.shape))\n",
    "\n",
    "clf_cv = LogisticRegressionCV(penalty = \"l1\", solver=\"liblinear\", cv=10, random_state = 10, max_iter = 1000).fit(X_train, y_train.ravel())\n",
    "\n",
    "y_train_pred = clf_cv.predict(X_train)\n",
    "print(\"Accurate percentage is\", sum(y_train_pred==y_train.squeeze())/len(y_train_pred) * 100 , '\\n')\n",
    "print(\"Coefficients are\", clf_cv.coef_)\n",
    "y_test_pred = clf_cv.predict(X_test)\n",
    "print(\"Accurate percentage is\", sum(y_test_pred==y_test.squeeze())/len(y_test) * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (229, 12), X_test (58, 12), y_train (229, 1), y_test (58, 1)\n",
      "Finished Training 350 545 553 749 757 955 963\n",
      "Train accuracy is 70.74235807860262\n",
      "Test accuracy is 51.724137931034484\n",
      "tensor([2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 2, 1, 0, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 2, 0, 2, 1, 2, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "#lets try and use deep learning to classify these surgeries!#\n",
    "#############################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "print(\"X_train {}, X_test {}, y_train {}, y_test {}\"\\\n",
    "      .format(X_train.shape,  X_test.shape, y_train.shape, y_test.shape))\n",
    "X_train_torch = torch.from_numpy(X_train).float()\n",
    "X_test_torch = torch.from_numpy(X_test).float()\n",
    "y_train_torch = torch.from_numpy(y_train.reshape((-1,))).long()\n",
    "y_test_torch = torch.from_numpy(y_test.reshape((-1,))).long()\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 30)\n",
    "        self.fc2 = nn.Linear(30, 3)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "my_nn = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(my_nn.parameters(), lr=10, momentum=0.9)\n",
    "optimizer = optim.Adam(my_nn.parameters(), lr=0.01, weight_decay = 0.01)\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "    print(\"Epoch\", epoch, end=\"\\r\")\n",
    "    my_nn.zero_grad()\n",
    "    log_probs = my_nn(X_train_torch)\n",
    "    loss = criterion(log_probs, y_train_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "y_train_pred = torch.argmax(my_nn(X_train_torch), 1)\n",
    "print(\"Train accuracy is\", int(sum(y_train_pred == y_train_torch))/len(y_train_torch)*100)\n",
    "\n",
    "y_test_pred = torch.argmax(my_nn(X_test_torch), 1)\n",
    "print(\"Test accuracy is\", int(sum(y_test_pred == y_test_torch))/len(y_test_torch)*100)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available!\n",
      "DONE!\n",
      "Epoch: 3/50... Step: 10... Loss: 0.441701... Val Loss: 0.584903\n",
      "Validation loss decreased (inf --> 0.584903).  Saving model ...\n",
      "Epoch: 5/50... Step: 20... Loss: 0.484858... Val Loss: 0.549209\n",
      "Validation loss decreased (0.584903 --> 0.549209).  Saving model ...\n",
      "Epoch: 8/50... Step: 30... Loss: 0.397890... Val Loss: 0.560622\n",
      "Epoch: 10/50... Step: 40... Loss: 0.605741... Val Loss: 0.530256\n",
      "Validation loss decreased (0.549209 --> 0.530256).  Saving model ...\n",
      "Epoch: 13/50... Step: 50... Loss: 0.324380... Val Loss: 0.553286\n",
      "Epoch: 15/50... Step: 60... Loss: 0.274066... Val Loss: 0.531741\n",
      "Epoch: 18/50... Step: 70... Loss: 0.701749... Val Loss: 0.573164\n",
      "Epoch: 20/50... Step: 80... Loss: 0.484483... Val Loss: 0.545286\n",
      "Epoch: 23/50... Step: 90... Loss: 0.607978... Val Loss: 0.571984\n",
      "Epoch: 25/50... Step: 100... Loss: 0.295293... Val Loss: 0.556961\n",
      "Epoch: 28/50... Step: 110... Loss: 0.468325... Val Loss: 0.531123\n",
      "Epoch: 30/50... Step: 120... Loss: 0.398252... Val Loss: 0.511622\n",
      "Validation loss decreased (0.530256 --> 0.511622).  Saving model ...\n",
      "Epoch: 33/50... Step: 130... Loss: 0.616519... Val Loss: 0.606815\n",
      "Epoch: 35/50... Step: 140... Loss: 0.566069... Val Loss: 0.549380\n",
      "Epoch: 38/50... Step: 150... Loss: 0.402935... Val Loss: 0.609225\n",
      "Epoch: 40/50... Step: 160... Loss: 0.463509... Val Loss: 0.443929\n",
      "Validation loss decreased (0.511622 --> 0.443929).  Saving model ...\n",
      "Epoch: 43/50... Step: 170... Loss: 0.625048... Val Loss: 0.577452\n",
      "Epoch: 45/50... Step: 180... Loss: -0.036003... Val Loss: 0.681255\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "#######################################################\n",
    "#lets try and use an LSTM to classify these surgeries!#\n",
    "#Inspired by a sentiment analyzer classifier          #\n",
    "#######################################################\n",
    "\n",
    "#https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/\n",
    "\n",
    "#max_video_length is 677, 5 second intervals\n",
    "#first, want to convert sequence dict into the same thing, but with\n",
    "#actions mapped to numbers. background=1, cutting=2, suturing=3, tying=4\n",
    "\n",
    "padded_dict = dict()\n",
    "for video in sequence_dict:\n",
    "    padded_dict[video] = []\n",
    "    for i, action in enumerate(sequence_dict[video]):\n",
    "        if action == \"background\": padded_dict[video].append(1)\n",
    "        elif action == \"cutting\": padded_dict[video].append(2)\n",
    "        elif action == \"suturing\": padded_dict[video].append(3)\n",
    "        elif action == \"tying\": padded_dict[video].append(4)\n",
    "#pad with 0's at the beginning\n",
    "for video in padded_dict:\n",
    "    while len(padded_dict[video]) < 677:\n",
    "        padded_dict[video].insert(0, 0)\n",
    "        \n",
    "LSTM_X = []\n",
    "LSTM_y = []\n",
    "for video in padded_dict:\n",
    "    LSTM_X.append(padded_dict[video])\n",
    "    LSTM_y.append(label_dict[video])\n",
    "\n",
    "LSTM_X = np.asarray(LSTM_X)\n",
    "LSTM_y = np.asarray(LSTM_y)\n",
    "\n",
    "X_train_LSTM, X_test_LSTM, y_train_LSTM, y_test_LSTM = train_test_split(LSTM_X, LSTM_y, test_size=0.2, random_state=102)\n",
    "\n",
    "X_train_LSTM = torch.FloatTensor(X_train_LSTM)\n",
    "y_train_LSTM = torch.FloatTensor(y_train_LSTM)\n",
    "X_test_LSTM = torch.FloatTensor(X_test_LSTM)\n",
    "y_test_LSTM = torch.FloatTensor(y_test_LSTM)\n",
    "\n",
    "train_data = TensorDataset(X_train_LSTM, y_train_LSTM)\n",
    "test_data = TensorDataset(X_test_LSTM, y_test_LSTM)\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last = True)\n",
    "val_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last = True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    print(\"CUDA Available!\")\n",
    "    \n",
    "##############################################DEFINE#NETWORK##############################################\n",
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "##############################################DEFINE#NETWORK##############################################\n",
    "\n",
    "vocab_size = 4 + 1\n",
    "output_size = 1\n",
    "embedding_dim = 1\n",
    "hidden_dim = 1000\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.0005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "print(\"DONE!\")\n",
    "\n",
    "epochs = 50\n",
    "counter = 0\n",
    "print_every = 10\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "229\n",
      "58\n",
      "Test loss: 0.568\n",
      "Test accuracy: 45.500%\n",
      "Test loss: 0.551\n",
      "Test accuracy: 40.000%\n"
     ]
    }
   ],
   "source": [
    "# Loading the best model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "num_correct = 0\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "tally = 0\n",
    "for inputs, labels in train_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    train_loss = criterion(output.squeeze(), labels.float())\n",
    "    train_losses.append(test_loss.item())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "    print(tally)\n",
    "    tally += 1\n",
    "print(len(train_loader.dataset))\n",
    "print(len(val_loader.dataset))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(train_losses)))\n",
    "test_acc = num_correct/200\n",
    "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))\n",
    "\n",
    "\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in val_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "test_acc = num_correct/50\n",
    "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genomizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Generate data....\n",
    "intervals, weights = [], []\n",
    "xticklabels = []\n",
    "max_weight = 5\n",
    "for video in gastro_videos:\n",
    "    if video[0:11] in action_dict and video[0:11] == \"aSnUUpTgYW0\":\n",
    "        print(\"Found one!\")\n",
    "        intervals.append(np.asarray(time_dict[video[0:11]]))\n",
    "        weights.append(np.asarray(action_dict[video[0:11]]))\n",
    "        xticklabels.append(video[0:11])\n",
    "        \n",
    "fig = plt.figure(figsize=(1, 10))\n",
    "# Plot the data as a stacked bar chart.\n",
    "for i, (interval, weight) in enumerate(zip(intervals, weights)):\n",
    "    # We need to calculate where the bottoms of the bars will be.\n",
    "    bottoms = np.r_[0, np.cumsum(interval[:-1])]\n",
    "\n",
    "    # We want the left edges to all be the same, but increase with each day.\n",
    "    left = len(interval) * [i]\n",
    "    patches = plt.bar(left, interval, bottom=bottoms, align='center')\n",
    "\n",
    "    # And set the colors of each bar based on the weights\n",
    "    for val, patch in zip(weight, patches):\n",
    "        # We need to normalize the \"weight\" value between 0-1 to feed it into\n",
    "        # a given colorbar to generate an actual color...\n",
    "        color = cm.jet(float(val) / max_weight)\n",
    "        patch.set_facecolor(color)\n",
    "   \n",
    "plt.yticks([])\n",
    "plt.xticks(range(0, len(xticklabels), 1), xticklabels, rotation=90)\n",
    "plt.xlim(-1, len(xticklabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Generate data....\n",
    "intervals, weights = [], []\n",
    "max_weight = 5\n",
    "for _ in range(1):\n",
    "    numtimes = np.random.randint(3, 15)\n",
    "    times = np.random.randint(1, 24*60 - 1, numtimes)\n",
    "    times = np.r_[0, times, 24*60]\n",
    "    times.sort()\n",
    "    intervals.append(np.diff(times) / 60.0)\n",
    "    weights.append(max_weight * np.random.random(numtimes + 1))\n",
    "    \n",
    "print(\"intervals are {} and weights are {}\".format(intervals, weights))\n",
    "\n",
    "# Plot the data as a stacked bar chart.\n",
    "for i, (interval, weight) in enumerate(zip(intervals, weights)):\n",
    "    # We need to calculate where the bottoms of the bars will be.\n",
    "    bottoms = np.r_[0, np.cumsum(interval[:-1])]\n",
    "\n",
    "    # We want the left edges to all be the same, but increase with each day.\n",
    "    left = len(interval) * [i]\n",
    "    patches = plt.bar(left, interval, bottom=bottoms, align='center')\n",
    "\n",
    "    # And set the colors of each bar based on the weights\n",
    "    for val, patch in zip(weight, patches):\n",
    "        # We need to normalize the \"weight\" value between 0-1 to feed it into\n",
    "        # a given colorbar to generate an actual color...\n",
    "        color = cm.jet(float(val) / max_weight)\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "# Setting the ticks and labels manually...\n",
    "plt.xticks(range(0, 30, 2), range(1, 31, 2))\n",
    "plt.yticks(range(0, 24 + 4, 4), \n",
    "           ['12am', '4am', '8am', '12pm', '4pm', '8pm', '12am'])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Hour')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#Creates dataset X, related to fraction of each action at each time#\n",
    "#X has dimensions [273,30]                                         #\n",
    "#this also creates labels y, and has dimensions [273,1]            #\n",
    "####################################################################\n",
    "\n",
    "partition = 10 #how many chunks to break a video into\n",
    "\n",
    "x = np.zeros((len(sequence_dict), 3*partition))\n",
    "y = np.empty((len(sequence_dict), 1))\n",
    "\n",
    "flag = False\n",
    "for vid_num, video in enumerate(sequence_dict):\n",
    "    tenth = int(len(sequence_dict[video])/partition)\n",
    "    for chunk in range(partition):\n",
    "        cutting, suturing, tying = 0, 0, 0\n",
    "        for frame in range(chunk*tenth, (chunk+1)*tenth):\n",
    "            if sequence_dict[video][frame] == \"cutting\":\n",
    "                cutting += 1\n",
    "            if sequence_dict[video][frame] == \"suturing\":\n",
    "                suturing += 1\n",
    "            if sequence_dict[video][frame] == \"tying\":\n",
    "                tying += 1\n",
    "        x[vid_num, 3*chunk+0] = cutting / tenth\n",
    "        x[vid_num, 3*chunk+1] = suturing / tenth\n",
    "        x[vid_num, 3*chunk+2] = tying / tenth\n",
    "    y[vid_num] = label_dict[video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of input data (x) is\", x.shape, \"and labels (y) are\", y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(\"X_train {}, X_test {}, y_train {}, y_test {}\".format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression using data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty=\"l1\", solver=\"saga\").fit(X_train, y_train.ravel())\n",
    "y_train_pred = clf.predict(X_train)\n",
    "#print(\"Predictions are\", y_train_pred)\n",
    "#print(\"True labels are\", y_train.squeeze())\n",
    "print(\"Accurate percentage is\", sum(y_train_pred==y_train.squeeze())/len(y_train_pred) * 100 , '\\n')\n",
    "\n",
    "key_weights0 = np.argsort(clf.coef_[0])[::-1]\n",
    "key_weights1 = np.argsort(clf.coef_[1])[::-1]\n",
    "key_weights2 = np.argsort(clf.coef_[2])[::-1]\n",
    "\n",
    "for weight in key_weights0:\n",
    "    if round(clf.coef_[0][weight], 2) != 0:\n",
    "        print(\"weight\", weight, \":\", round(clf.coef_[0][weight], 2), end = '    ')\n",
    "print('\\n')\n",
    "for weight in key_weights1:\n",
    "    if round(clf.coef_[1][weight], 2) != 0:\n",
    "        print(\"weight\", weight, \":\", round(clf.coef_[1][weight], 2), end = '    ')\n",
    "print('\\n')\n",
    "for weight in key_weights2:\n",
    "    if round(clf.coef_[2][weight], 2) != 0:\n",
    "        print(\"weight\", weight, \":\", round(clf.coef_[2][weight], 2), end = '    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cutting_weights = [weights for (i, weights) in enumerate(clf.coef_[0]) if i%3==0]\n",
    "breast_suturing_weights = [weights for (i, weights) in enumerate(clf.coef_[0]) if i%3==1]\n",
    "breast_tying_weights = [weights for (i, weights) in enumerate(clf.coef_[0]) if i%3==2]\n",
    "gastro_cutting_weights = [weights for (i, weights) in enumerate(clf.coef_[1]) if i%3==0]\n",
    "gastro_suturing_weights = [weights for (i, weights) in enumerate(clf.coef_[1]) if i%3==1]\n",
    "gastro_tying_weights = [weights for (i, weights) in enumerate(clf.coef_[1]) if i%3==2]\n",
    "head_cutting_weights = [weights for (i, weights) in enumerate(clf.coef_[2]) if i%3==0]\n",
    "head_suturing_weights = [weights for (i, weights) in enumerate(clf.coef_[2]) if i%3==1]\n",
    "head_tying_weights = [weights for (i, weights) in enumerate(clf.coef_[2]) if i%3==2]\n",
    "\n",
    "ind = np.arange(partition)    # the x locations for the groups\n",
    "width = .9       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_figheight(2.5)\n",
    "fig.set_figwidth(9)\n",
    "\n",
    "ax1.bar(ind, breast_tying_weights, color='b')\n",
    "ax1.set_ylim(-1.6, 1.6); ax1.tick_params(bottom=False, labelbottom=False, left=False, labelleft=False) \n",
    "ax2.bar(ind, gastro_tying_weights, color='g')\n",
    "ax2.set_ylim(-1.6, 1.6); ax2.tick_params(bottom=False, labelbottom=False, left=False, labelleft=False) \n",
    "ax3.bar(ind, head_tying_weights, color='r')\n",
    "ax3.set_ylim(-1.6, 1.6); ax3.tick_params(bottom=False, labelbottom=False, left=False, labelleft=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Predictions are\", y_test_pred)\n",
    "print(\"True labels are\", y_test.squeeze())\n",
    "print(\"Accurate percentage is\", sum(y_test_pred==y_test.squeeze())/len(y_test_pred) * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(x).float()\n",
    "Y = torch.from_numpy(y).squeeze().long()\n",
    "\n",
    "Xtrain = X[0:200,:]\n",
    "Xtest = X[200:, :]\n",
    "print(X.shape, Xtrain.shape, Xtest.shape)\n",
    "Ytrain = Y[0:200]\n",
    "Ytest = Y[200:]\n",
    "print(Y.shape, Ytrain.shape, Ytest.shape)\n",
    "dataset_statistics(Y)\n",
    "dataset_statistics(Ytrain)\n",
    "dataset_statistics(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_statistics(y):\n",
    "    mydict = dict()\n",
    "    total = 0\n",
    "    for ex in y:\n",
    "        if int(ex) in mydict:\n",
    "            mydict[int(ex)] += 1\n",
    "        else:\n",
    "            mydict[int(ex)] = 1\n",
    "        total += 1\n",
    "    for ex in mydict:\n",
    "        print(\"Found {} of class {}\".format(mydict[int(ex)]/len(y) * 100, int(ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(40, 20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(20,10)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(10,3)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params, \"total parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=.003, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    # inputs, labels = data\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(Xtrain)\n",
    "    loss = criterion(outputs, Ytrain)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if epoch % 100 == 0:    # print every 2000 mini-batches\n",
    "        print(\"Training epoch\", epoch, 'with running loss', running_loss, end=\"\\r\")\n",
    "\n",
    "print('\\nFinished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check train data\n",
    "Predictions = net(Xtrain.float())\n",
    "Ytrain_pred = torch.argmax(Predictions, axis=1)\n",
    "print(\"Predicted\", Ytrain_pred)\n",
    "print(\"Actual\", Ytrain)\n",
    "print(\"Accurate fraction is\", int(sum(Ytrain==Ytrain_pred))/len(Ytrain) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check train data\n",
    "Predictions = net(Xtest.float())\n",
    "Ytest_pred = torch.argmax(Predictions, axis=1)\n",
    "print(\"Predicted\", Ytest_pred)\n",
    "print(\"Actual\", Ytest)\n",
    "print(\"Accurate fraction is\", int(sum(Ytest==Ytest_pred))/len(Ytest) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "breast_dict = {\"background\":[], \"cutting\":[], \"suturing\":[], \"tying\":[]}\n",
    "gastro_dict = {\"background\":[], \"cutting\":[], \"suturing\":[], \"tying\":[]}\n",
    "head_dict = {\"background\":[], \"cutting\":[], \"suturing\":[], \"tying\":[]}\n",
    "\n",
    "flag = False\n",
    "for vid_num, video in enumerate(sequence_dict):\n",
    "    #print(\"Analyzing video\", video, 'from class', label_dict[video])\n",
    "    background, cutting, suturing, tying = 0, 0, 0, 0\n",
    "    for action in sequence_dict[video]:\n",
    "        if action == \"background\":\n",
    "            background += 1\n",
    "        elif action == \"cutting\":\n",
    "            cutting += 1\n",
    "        elif action == \"suturing\":\n",
    "            suturing += 1\n",
    "        elif action == \"tying\":\n",
    "            tying += 1\n",
    "    if label_dict[video] == 0:\n",
    "        breast_dict[\"background\"].append(background/len(sequence_dict[video]))\n",
    "        breast_dict[\"cutting\"].append(cutting/len(sequence_dict[video]))\n",
    "        breast_dict[\"suturing\"].append(suturing/len(sequence_dict[video]))\n",
    "        breast_dict[\"tying\"].append(tying/len(sequence_dict[video]))\n",
    "    elif label_dict[video] == 1:\n",
    "        gastro_dict[\"background\"].append(background/len(sequence_dict[video]))\n",
    "        gastro_dict[\"cutting\"].append(cutting/len(sequence_dict[video]))\n",
    "        gastro_dict[\"suturing\"].append(suturing/len(sequence_dict[video]))\n",
    "        gastro_dict[\"tying\"].append(tying/len(sequence_dict[video]))\n",
    "    elif label_dict[video] == 2:\n",
    "        head_dict[\"background\"].append(background/len(sequence_dict[video]))\n",
    "        head_dict[\"cutting\"].append(cutting/len(sequence_dict[video]))\n",
    "        head_dict[\"suturing\"].append(suturing/len(sequence_dict[video]))\n",
    "        head_dict[\"tying\"].append(tying/len(sequence_dict[video]))\n",
    "        \n",
    "print(\"Breast : background {}, cutting {}, suturing {}, tying {}\".\\\n",
    "      format(np.mean(breast_dict[\"background\"]), np.mean(breast_dict[\"cutting\"]), np.mean(breast_dict[\"suturing\"]), np.mean(breast_dict[\"tying\"])))\n",
    "print(\"Breast : background {}, cutting {}, suturing {}, tying {} \\n\".\\\n",
    "      format(np.std(breast_dict[\"background\"]), np.std(breast_dict[\"cutting\"]), np.std(breast_dict[\"suturing\"]), np.std(breast_dict[\"tying\"])))\n",
    "\n",
    "print(\"Gastro : background {}, cutting {}, suturing {}, tying {}\".\\\n",
    "      format(np.mean(gastro_dict[\"background\"]), np.mean(gastro_dict[\"cutting\"]), np.mean(gastro_dict[\"suturing\"]), np.mean(gastro_dict[\"tying\"])))\n",
    "print(\"Gastro : background {}, cutting {}, suturing {}, tying {} \\n\".\\\n",
    "      format(np.std(gastro_dict[\"background\"]), np.std(gastro_dict[\"cutting\"]), np.std(gastro_dict[\"suturing\"]), np.std(gastro_dict[\"tying\"])))\n",
    "\n",
    "\n",
    "print(\"Head : background {}, cutting {}, suturing {}, tying {}\".\\\n",
    "      format(np.mean(head_dict[\"background\"]), np.mean(head_dict[\"cutting\"]), np.mean(head_dict[\"suturing\"]), np.mean(head_dict[\"tying\"])))    \n",
    "print(\"Head : background {}, cutting {}, suturing {}, tying {}\".\\\n",
    "      format(np.std(head_dict[\"background\"]), np.std(head_dict[\"cutting\"]), np.std(head_dict[\"suturing\"]), np.std(head_dict[\"tying\"])))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#######################################\n",
    "#for simple bar charts vs surgery type#\n",
    "#######################################\n",
    "\n",
    "background = (np.mean(breast_dict[\"background\"]), np.mean(gastro_dict[\"background\"]), np.mean(head_dict[\"background\"])) \n",
    "cutting = (np.mean(breast_dict[\"cutting\"]), np.mean(gastro_dict[\"cutting\"]), np.mean(head_dict[\"cutting\"])) \n",
    "suturing = (np.mean(breast_dict[\"suturing\"]), np.mean(gastro_dict[\"suturing\"]), np.mean(head_dict[\"suturing\"])) \n",
    "tying = (np.mean(breast_dict[\"tying\"]), np.mean(gastro_dict[\"tying\"]), np.mean(head_dict[\"tying\"])) \n",
    "\n",
    "p3 = background+cutting\n",
    "              \n",
    "ind = np.arange(3)    # the x locations for the groups\n",
    "width = .9       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig = plt.figure(figsize=(3, 6))\n",
    "\n",
    "p1 = plt.bar(ind, background, width, color = 'b')\n",
    "p1 = plt.bar(ind, cutting, width, bottom = background, color = 'g' )\n",
    "p1 = plt.bar(ind, suturing, width, bottom = [i+j for i, j in zip(background, cutting)], color = 'r')\n",
    "p1 = plt.bar(ind, tying, width, bottom = [i+j+k for i, j, k in zip(background, cutting, suturing)], color = 'm')\n",
    "\n",
    "#p1 = plt.bar(ind, means, width, yerr=stds, color = ['b', 'r', 'g'])\n",
    "\n",
    "plt.ylabel('Fraction of video', fontsize=14)\n",
    "plt.xticks(ind, ('Breast', 'Gastro', 'Head'), fontsize=14)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, .1))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# super simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating network\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()  \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size) #not used yet\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        hidden = hidden.reshape(hidden.shape[1], hidden.shape[2]*hidden.shape[0])\n",
    "        hidden = self.fc(hidden)\n",
    "        hidden = self.sm(hidden)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        print(\"Hidden size is\", hidden.shape)\n",
    "        return hidden\n",
    "    \n",
    "model = Model(input_size=4, output_size=3, hidden_dim=100, n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "#https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677\n",
    "n_epochs = 2500\n",
    "lr=0.003\n",
    "model = Model(input_size=4, output_size=3, hidden_dim=100, n_layers=1)\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = .001)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    Xtrain.to(device)\n",
    "    output = model(Xtrain)\n",
    "    loss = criterion(output, Ytrain)\n",
    "    #print(\"Calculated loss!\", loss)\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f} \\r\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YPred = model(Xtrain)\n",
    "int(sum(Ytrain==torch.argmax(YPred, axis=1)))/len(Ytrain)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YPred = model(Xtest)\n",
    "int(sum(Ytest==torch.argmax(YPred, axis=1)))/len(Ytest)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#characteristics of all surgeries\n",
    "\n",
    "xfilter = []\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 2:\n",
    "        xfilter.append(x[i,:])\n",
    "xfilter = np.asarray(xfilter)\n",
    "\n",
    "condensedX = np.mean(xfilter, axis=0)\n",
    "cuts = [condensedX[i] for i in range(len(condensedX)) if i % 3 == 0]; #cuts /= max(cuts)\n",
    "sutures = [condensedX[i] for i in range(len(condensedX)) if i % 3 == 1]; #sutures /= max(sutures)\n",
    "ties = [condensedX[i] for i in range(len(condensedX)) if i % 3 == 2]; #ties /= max(ties)\n",
    "\n",
    "ind = np.arange(partition)    # the x locations for the groups\n",
    "width = .9       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig = plt.figure(figsize=(2, 6))\n",
    "\n",
    "ax1 = plt.subplot(311)\n",
    "plt.bar(ind, cuts, color='r')\n",
    "plt.xticks([], [])\n",
    "plt.ylim(-1, 1); plt.yticks([], [])\n",
    "ax2 = plt.subplot(312)\n",
    "plt.bar(ind, sutures, color='r')\n",
    "plt.xticks([], [])\n",
    "plt.ylim(-1, 1); plt.yticks([], [])\n",
    "ax3 = plt.subplot(313)\n",
    "plt.bar(ind, ties, color='r')\n",
    "plt.xticks([], [])\n",
    "plt.ylim(-1, 1); plt.yticks([], [])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
